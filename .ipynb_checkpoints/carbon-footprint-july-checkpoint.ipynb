{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70e846a",
   "metadata": {},
   "source": [
    "# Calculating Carbon Footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32103f24",
   "metadata": {},
   "source": [
    "## Preparing the Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8bb58",
   "metadata": {},
   "source": [
    "We will first import all of the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07397f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ffd54",
   "metadata": {},
   "source": [
    "We will now set up our jupyter notebook to make queries from VictoriaMetrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2820a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'FBmZiWNJxiiwGfHzNvX436VdWqYtRLv6hb7FfiMyjgV9FAhEktpwJM2GHPJKCif6'\n",
    "proxies = {\n",
    "    'http': 'socks5://localhost:49152',\n",
    "    'https': 'socks5://localhost:49152'\n",
    "}\n",
    "url = 'http://128.232.227.113:8427/api/v1/query_range'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {token}',\n",
    "    'Accept': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e83e9a",
   "metadata": {},
   "source": [
    "## Loading in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f2c29",
   "metadata": {},
   "source": [
    "We have saved the processed Slurm data in csv files, which we will now load into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b79939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now read the .csv file containing the Slurm data for June into a DataFrame\n",
    "sSlurmDataPath = 'dfSacctFinal.csv'\n",
    "dfSacct = pd.read_csv(sSlurmDataPath, index_col=0, parse_dates=['Start', 'End'], infer_datetime_format=True)\n",
    "\n",
    "# We will now read the .csv file containing the extended Slurm data for June into a DataFrame. \n",
    "sSlurmExtendedPath = 'dfSacctExtended.csv'\n",
    "dfSacctExtended = pd.read_csv(sSlurmExtendedPath, index_col=0, parse_dates=['Start', 'End'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff63690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_9284\\2537312781.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dfSacctExtended[dfSacctExtended.index.value_counts() == 1].iloc[800000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JobName                 5d3c85e3f26d6cfe24edd5043806e4ee1573ad96de5c1c...\n",
       "Partition                                                          cclake\n",
       "ElapsedRaw                                                            853\n",
       "Account                 e14914f6ebb1765cfacdab633295f51cbc9a39bc1057f8...\n",
       "State                                                           COMPLETED\n",
       "NodeList                                                        cpu-p-399\n",
       "User                    3f325dc5f73f566e06e2f7f1cb447d78fc3c2aeeab7860...\n",
       "QOS                                                                  cpu1\n",
       "Start                                                 2023-07-24 10:22:37\n",
       "End                                                   2023-07-24 10:36:50\n",
       "Timelimit                                                        01:00:00\n",
       "Suspended                                                        00:00:00\n",
       "ExclusiveCPU                                                        False\n",
       "ExclusiveOverlapping                                                False\n",
       "Exclusive                                                           False\n",
       "SharedSameUser                                                      False\n",
       "Name: 24215221, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSacctExtended[dfSacctExtended.index.value_counts() == 1].iloc[800000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba1639",
   "metadata": {},
   "source": [
    "## Ensuring the Time is in UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d6bdb0",
   "metadata": {},
   "source": [
    "We must first ensure that all times are in UTC so that we access the correct power readings from Victoria Metrics. \n",
    "\n",
    "We will first create a function that converts a series of times from local time to UTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef638a9",
   "metadata": {},
   "source": [
    "We will create a function to convert all times in the DataFrame to UTC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3237c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfToUTC(df):\n",
    "    \"\"\"\n",
    "    Returns a pd DataFrame containing columns for the start and end times in UTC.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pdDataFrame \n",
    "        The pd DataFrame containing all of the job data. This DataFrame must contain \n",
    "        a 'Start' and 'End' column of pd DateTime64 objects. \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    df: pdDataFrame\n",
    "        The pd DataFrame that was passed in as a parameter with two new columns:\n",
    "        'StartUTC' and 'EndUTC' of pd DateTime64 objects, which contain the original \n",
    "        start and end times in UTC rather than local time. \n",
    "    \"\"\"\n",
    "\n",
    "    df['UTCStart'] = df['Start'].dt.tz_localize('Europe/London')\n",
    "    df['UTCEnd'] = df['End'].dt.tz_localize('Europe/London')\n",
    "\n",
    "    df['UTCStart'] = df['UTCStart'].dt.tz_convert(pytz.utc)\n",
    "    df['UTCEnd'] = df['UTCEnd'].dt.tz_convert(pytz.utc)\n",
    "\n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a36ee",
   "metadata": {},
   "source": [
    "We will now apply our function to the *dfSacctExtended* DataFrame in order to get the times in UTC rather than local time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdbea43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSacctExtended = dfToUTC(dfSacctExtended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e0407",
   "metadata": {},
   "source": [
    "## Querying Victoria Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f7666",
   "metadata": {},
   "source": [
    "Rather than constantly querying Victoria Metrics, we will query Victoria Metrics once at the start and store all of the power data for all of the nodes across the entire time period in a .csv file called *VMPowerJune.csv*.\n",
    "\n",
    "We will now create a function that checks whether the file *VMPowerJune.csv* exists. If it exists, the function will return a DataFrame containing the data in the .csv file. If it does not exist, the function will query Victoria Metrics and will create the file *VMPowerJune.csv* to store the data. The function will then return a DataFrame containig the power data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d448fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPowerDataMonth(dfJobs):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing the Victoria Metrics power data for the specified month.\n",
    "\n",
    "    Checks whether the .csv file containing the Victoria Metrics power data for the specified \n",
    "    month (with the format 'VMPower<Month>.csv') exists. If the file exists the DataFrame \n",
    "    containing the power data is returned. If the file does not exist, Victoria Metrics is \n",
    "    queried and the .csv file is created; the function then returns the DataFrame containing\n",
    "    the power data. If there is a problem while querying Victoria Metrics, the function will \n",
    "    return None.\n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "    dfJobs: pdDataFrame\n",
    "        The DataFrame containing all of the job data that is to be processed. This DataFrame \n",
    "        must have already been processed to contain UTCStart and UTCEnd columns. This can be \n",
    "        done using the dfToUTC() function. \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dfPower: pdDataFrame\n",
    "        The DataFrame containing all of the power data. \n",
    "    None: NoneType\n",
    "        Returned if there is a problem while querying Victoria Metrics.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # We start by obtaining the file name from the input string\n",
    "    sMonth = dfJobs['UTCStart'].dt.month_name(locale='English').value_counts().index[0]\n",
    "    sFileName = 'VMPower' + sMonth + '.csv'\n",
    "\n",
    "    # We will now open the file and check whether it is empty. If the file is \n",
    "    # empty we will query Victoria Metrics and obtain the data. If the file is \n",
    "    # not empty we will load in the data and return a DataFrame. \n",
    "    fPowerData = open(sFileName, 'a+')\n",
    "    fPowerData.seek(0)\n",
    "\n",
    "    if len(fPowerData.read()) == 0:\n",
    "        # We will now obtain the start and end dates and times for our query.\n",
    "        start = dfJobs.iloc[0]['UTCStart'].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        end = dfJobs.iloc[-1]['UTCEnd'].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        # We will now query Victoria Metrics to obtain the power data\n",
    "        data = {\n",
    "            'query': f'amperageProbeReading{{amperageProbeLocationName=\"System Board Pwr Consumption\"}}',\n",
    "            'start': start,\n",
    "            'end' : end,\n",
    "            'step': '30s'\n",
    "        }\n",
    "\n",
    "        response = requests.put(\n",
    "            url, \n",
    "            data=data,\n",
    "            proxies=proxies,\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )  \n",
    "\n",
    "        # We will now ensure that the request was successfull \n",
    "        if (response.status_code != 200):\n",
    "            return None\n",
    "\n",
    "        # We will now create a DataFrame containing the power data\n",
    "        dNodePowers = {}\n",
    "        lTicks = []\n",
    "\n",
    "        for dNodeData in response.json()['data']['result']:\n",
    "            sNode = dNodeData['metric']['alias']\n",
    "            lData = dNodeData['values']\n",
    "\n",
    "            dNodePowers[sNode] = lData\n",
    "\n",
    "            for lDataPoint in lData:\n",
    "                lTicks.append(lDataPoint[0])\n",
    "\n",
    "        lTicks.sort()\n",
    "        setTicksOrdered = set(lTicks)\n",
    "\n",
    "        dfJobPower = pd.DataFrame(\n",
    "            response.json()['data']['result'][0]['values'],\n",
    "            columns=[\n",
    "                'Timestamp',\n",
    "                response.json()['data']['result'][0]['metric']['alias']\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    fPowerData.close()\n",
    "\n",
    "    return setTicksOrdered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11932dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "getPowerDataMonth(dfSacctExtended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226216f5",
   "metadata": {},
   "source": [
    "## Obtaining the Power Reading "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ab253",
   "metadata": {},
   "source": [
    "We first need to floor the start times and ceil the end times to the nearest 30s to ensure that we do not miss out any of the Victoria metrics data (as the data is sampled every 30s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c86ff",
   "metadata": {},
   "source": [
    "We will now write a function to get the power reading for a given job from VictoriaMetrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fdd45020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPowerJob(jobID, df):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of the total power usage of the job for each 30 minute time period. \n",
    "\n",
    "    Returns a dictionary of the total power usage of the job (across each node) for each 30 \n",
    "    minute time period of the job duration. The keys of the dictionary are a string of the \n",
    "    format \"YYYY-MM-DD PERIOD\" where PERIOD represents the 30 minute time period for that day \n",
    "    as an integer from 1-48. The values of the dictionary are total power consumptions of the \n",
    "    job, in Wh, for each 30 minute period.\n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "    jobID: string\n",
    "        A string representing the Job ID for the specified job. \n",
    "    df: pdDataFrame\n",
    "        The pandas DataFrame containing all the job data.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    dIntervalPowers: dictionary \n",
    "        A dictionary of the total power usage of the job, in Wh, for each 30 minute interval. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    jobID = int(jobID)\n",
    "    \n",
    "    if df.index.value_counts().loc[jobID] <= 1:\n",
    "        sNode = df.loc[jobID, 'NodeList']\n",
    "        return getPowerNode(jobID, df, sNode)\n",
    "    \n",
    "    lNodeList = list(df.loc[jobID, 'NodeList'])\n",
    "\n",
    "    dTotalWattHours = {}\n",
    "\n",
    "    for sNode in lNodeList:\n",
    "        dWattHours = getPowerNode(jobID, df, sNode)\n",
    "\n",
    "        lPeriods = list(dWattHours.keys())\n",
    "\n",
    "        for sPeriod in lPeriods:\n",
    "            if dWattHours[sPeriod] is None:\n",
    "                return None\n",
    "            \n",
    "            if sPeriod in dTotalWattHours.keys():\n",
    "                dTotalWattHours[sPeriod] += dWattHours[sPeriod]\n",
    "            else:\n",
    "                dTotalWattHours[sPeriod] = dWattHours[sPeriod]\n",
    "\n",
    "    return dTotalWattHours\n",
    "\n",
    "def getPowerNode(jobID, df, sNode):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of the power usage of a single node for each 30 minute time period.\n",
    "\n",
    "    Returns a dictionary of the power usage of the job for a single node for each 30 minute\n",
    "    time period of the job duration. The keys of the dictionary are a string of the format \n",
    "    \"YYYY-MM-DD PERIOD\" where PERIOD represents the 30 minute time period for that day as an \n",
    "    integer from 1-48. The values of the dictionary are total power consumptions of the job, \n",
    "    in Wh, for each 30 minute period.\n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "    jobID: string\n",
    "        A string representing the Job ID for the specified job. \n",
    "    df: pdDataFrame\n",
    "        The pandas DataFrame containing all the job data.\n",
    "    sNode: string\n",
    "        The node name that the job is running on. \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    dIntervalPowers: dictionary \n",
    "        A dictionary of the power usage of the job for a single node, in Wh, for each 30 \n",
    "        minute interval. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    jobID = int(jobID)\n",
    "\n",
    "    start = df[df['NodeList'] == sNode].loc[jobID, 'UTCStart'].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    end = df[df['NodeList'] == sNode].loc[jobID, 'UTCEnd'].strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    " \n",
    "    data = {\n",
    "        'query': f'amperageProbeReading{{alias=\"{sNode}\", amperageProbeLocationName=\"System Board Pwr Consumption\"}}',\n",
    "        'start': start,\n",
    "        'end' : end,\n",
    "        'step': '30s'\n",
    "    }\n",
    "\n",
    "    response = requests.put(\n",
    "        url, \n",
    "        data=data,\n",
    "        proxies=proxies,\n",
    "        headers=headers,\n",
    "        timeout=10\n",
    "    )  \n",
    "\n",
    "\n",
    "    if len(response.json()['data']['result']) < 1:\n",
    "        return None\n",
    "\n",
    "    dfJobPower = pd.DataFrame(\n",
    "        response.json()['data']['result'][0]['values'],\n",
    "        columns=[\n",
    "            'Timestamp',\n",
    "            response.json()['data']['result'][0]['metric']['alias']\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # The following is used as test data\n",
    "\n",
    "    lPowerTest = []\n",
    "\n",
    "    for tTick in list(range(1690355610, 1690360500, 30)):\n",
    "        if tTick < (1690355610 + 1800):\n",
    "            lPowerTest.append([tTick, 300])\n",
    "        elif (1690355610 + 1800) < tTick and tTick < (1690355610 + 3089):\n",
    "            lPowerTest.append([tTick, 150])\n",
    "        elif tTick > (1690355610 + 3089):\n",
    "            lPowerTest.append([tTick, 300])\n",
    "\n",
    "    if jobID == 0:\n",
    "        dfJobPower = pd.DataFrame(\n",
    "            lPowerTest,\n",
    "            columns=['Timestamp', 'Test']\n",
    "        )\n",
    "\n",
    "    dfJobPower['Timestamp'] = pd.to_datetime(dfJobPower['Timestamp'], unit='s', utc=True)\n",
    "    dfJobPower['Date'] = dfJobPower['Timestamp'].dt.strftime('%Y-%m-%d')\n",
    "    dfJobPower['Date'] = dfJobPower['Date'].str.cat((((dfJobPower['Timestamp']).dt.hour * 2) + ((dfJobPower['Timestamp']).dt.minute//30) + 1).astype(str), sep=\" \")\n",
    "    dfJobPower.set_index('Timestamp', inplace=True)\n",
    "\n",
    "    dIntervalPowers = {}\n",
    "\n",
    "    print(dfJobPower)\n",
    "\n",
    "    for interval in dfJobPower['Date'].unique():\n",
    "        bIntervalMask = dfJobPower['Date'] == interval\n",
    "\n",
    "        dfIntervalPower = dfJobPower[bIntervalMask]\n",
    "        dfIntervalPower[sNode] = pd.to_numeric(dfIntervalPower[sNode])\n",
    "        dfIntervalPower = dfIntervalPower.resample('30S').interpolate()\n",
    "\n",
    "        iJoules = np.trapz(dfIntervalPower[sNode].astype(int), dx=30)\n",
    "        iWattHour = iJoules/3600\n",
    "\n",
    "        dIntervalPowers[interval] = iWattHour\n",
    "\n",
    "    return dIntervalPowers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d89bbf",
   "metadata": {},
   "source": [
    "In order to get the carbon intensity from the carbonintensity.org API, we need to know the time periods that we are intersted in. These time periods are the half hour settlement periods between 1-48 for each day. We will now write a function to return the time period(s) that we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "407e9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimePeriods(start, end):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the 30 minute time periods for each day within an interval. \n",
    "\n",
    "    Returns a dictionary whose keys are the dates, with the format 'YYYY-MM-DD', within the \n",
    "    given interval and values are lists of the 30 minute time intervals (which are integers\n",
    "    from 1-48) that are included in the given time period for each day.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sStart: string\n",
    "        A string representing the start date and time of the interval. \n",
    "    sEnd: string\n",
    "        A string representing the end date and time of the interval. \n",
    "\n",
    "    Returns \n",
    "    ----------\n",
    "    dPeriods: dictionary \n",
    "        A dictionary containing the 30 minute intervals included in each day of the specified\n",
    "        time period. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # We first convert the string variables representing the start and end times to DataTime objects. \n",
    "\n",
    "    # We then create variables for the start and end dates. \n",
    "    startDate = start.date()\n",
    "    endDate = end.date()\n",
    "\n",
    "    iStartSegment = (start.hour * 2) + (start.minute//30) + 1\n",
    "    iEndSegment = (end.hour * 2) + (end.minute//30) + 1\n",
    "\n",
    "    iDaySeparation = (endDate - startDate).days\n",
    "\n",
    "    dPeriods = {startDate.strftime(\"%Y-%m-%d\") : list(range(iStartSegment, 49)), endDate.strftime(\"%Y-%m-%d\") : list(range(1, iEndSegment + 1))}\n",
    "\n",
    "    if iDaySeparation == 0:\n",
    "        return {startDate.strftime(\"%Y-%m-%d\") : list(range(iStartSegment, iEndSegment + 1))}\n",
    "    else:\n",
    "        for iCount in range(iDaySeparation):\n",
    "            day = startDate + pd.Timedelta(iCount, 'days')\n",
    "            \n",
    "            if day != startDate:\n",
    "                dPeriods[day.strftime(\"%Y-%m-%d\")] = list(range(1, 49))\n",
    "            \n",
    "\n",
    "    return dPeriods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49310551",
   "metadata": {},
   "source": [
    "We will now create a function that returns a list of all the carbon intensities that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee1edeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCarbonIntensities(start, end):\n",
    "    \"\"\" \n",
    "    Returns a dictionary of the carbon intensities for each 30 minute time period in the interval.\n",
    "\n",
    "    Returns a dictionary whose keys are the dates, in the format 'YYYY-MM-DD', within the given\n",
    "    interval and whose values are lists of the carbon intensities, in gCO2/kWh, for each 30 minute \n",
    "    time period for each day within the interval. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sStart: string\n",
    "        A string representing the start date and time of the interval. \n",
    "    sEnd: string\n",
    "        A string representing the end date and time of the interval. \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    dIntensities: dictionary \n",
    "        A dictionary containing the carbon intensity, in gCO2/kWh, for each 30 minute interval within\n",
    "        the specified time range. \n",
    "    \"\"\"\n",
    "    dPeriods = getTimePeriods(start, end)\n",
    "\n",
    "    lDates = list(dPeriods.keys())\n",
    "    lDates.sort()\n",
    "\n",
    "    dIntensities = {}\n",
    "\n",
    "    for date in lDates:\n",
    "        for period in dPeriods[date]:\n",
    "            intensity = requests.get(f'https://api.carbonintensity.org.uk/intensity/date/{date}/{period}')\n",
    "            dIntensities[str(date) + \" \" + str(period)] = (intensity.json()['data'][0]['intensity']['actual'])\n",
    "\n",
    "    return dIntensities\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e261731",
   "metadata": {},
   "source": [
    "We will now write a function to calculate the carbon footprint given the Watt Hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7f3b3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCarbonFootprint(jobID, df):\n",
    "    \"\"\"\n",
    "    Returns the carbon footprint, in g, of the specified job. \n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "    jobID: string\n",
    "        The job ID of the job whose carbon footprint is calculated.\n",
    "    df: pdDataFrame\n",
    "        The pandas DataFrame containing all the job data.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    iTotalCarbon: integer\n",
    "        The total carbon released, in g, due to the energy consumption of the job. \n",
    "    \"\"\"\n",
    "\n",
    "    jobID = int(jobID)\n",
    "\n",
    "    start = df.loc[jobID, 'UTCStart'].unique()[0]\n",
    "    end = df.loc[jobID, 'UTCEnd'].unique()[0]\n",
    "    \n",
    "    dIntervalPowers = getPowerJob(jobID, df)\n",
    "    dIntervalIntensities = getCarbonIntensities(start, end)\n",
    "\n",
    "    iTotalCarbon = 0\n",
    "\n",
    "    for interval in dIntervalPowers.keys():\n",
    "        iWattHour = dIntervalPowers[interval]\n",
    "        iKWattHours = iWattHour/1000\n",
    "\n",
    "        iIntensity = dIntervalIntensities[interval]\n",
    "\n",
    "        iCarbon = iIntensity * iKWattHours\n",
    "\n",
    "        iTotalCarbon += iCarbon\n",
    "\n",
    "    return iTotalCarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "20699952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.13365\n"
     ]
    }
   ],
   "source": [
    "print(getCarbonFootprint('24177267', dfSacctExtended))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ba93488c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39mjson())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347fd0b",
   "metadata": {},
   "source": [
    "In order to test the carbon footprint code above, I am going to create some test power reading data which will have the following structure: \n",
    "\n",
    "    - A power of 300 W for the first 1800 seconds.\n",
    "    - A power of 150 W for the next 1289 seconds. \n",
    "    - A power of 300 W for the next 1800 seconds.\n",
    "\n",
    "The total energy consumed by this test job should be 735 450 J or 204.292 wh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ab0338e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_27928\\1080419065.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dfTest = dfSacctExtended[dfSacctExtended.index.value_counts() == 1].iloc[-1].to_frame().transpose().reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "dfTest = dfSacctExtended[dfSacctExtended.index.value_counts() == 1].iloc[-1].to_frame().transpose().reset_index(drop=True)\n",
    "\n",
    "dfTest['End'] = pd.to_datetime(\"2023-07-27 09:35:05\")\n",
    "dfTest['UTCEnd'] = pd.to_datetime(\"2023-07-27 08:35:05+00:00\")\n",
    "dfTest['NodeList'] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f4a44406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobName</th>\n",
       "      <th>Partition</th>\n",
       "      <th>ElapsedRaw</th>\n",
       "      <th>Account</th>\n",
       "      <th>State</th>\n",
       "      <th>NodeList</th>\n",
       "      <th>User</th>\n",
       "      <th>QOS</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Timelimit</th>\n",
       "      <th>Suspended</th>\n",
       "      <th>ExclusiveCPU</th>\n",
       "      <th>ExclusiveOverlapping</th>\n",
       "      <th>Exclusive</th>\n",
       "      <th>SharedSameUser</th>\n",
       "      <th>UTCStart</th>\n",
       "      <th>UTCEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171f8e926c82dd83fc75053ec9b110f092aa32b41d5c98...</td>\n",
       "      <td>ampere</td>\n",
       "      <td>29</td>\n",
       "      <td>99fdc1f587a9423c1abc5a1ce22053628b94a5226d3c0f...</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>cpu-p-399</td>\n",
       "      <td>dd68b7c728069b005e5dac9c3e9d59a7379b1347fa4e6f...</td>\n",
       "      <td>gpu2</td>\n",
       "      <td>2023-07-27 08:13:36</td>\n",
       "      <td>2023-07-27 09:35:05</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-07-27 07:13:36+00:00</td>\n",
       "      <td>2023-07-27 08:35:05+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             JobName Partition ElapsedRaw  \\\n",
       "0  171f8e926c82dd83fc75053ec9b110f092aa32b41d5c98...    ampere         29   \n",
       "\n",
       "                                             Account      State   NodeList  \\\n",
       "0  99fdc1f587a9423c1abc5a1ce22053628b94a5226d3c0f...  COMPLETED  cpu-p-399   \n",
       "\n",
       "                                                User   QOS  \\\n",
       "0  dd68b7c728069b005e5dac9c3e9d59a7379b1347fa4e6f...  gpu2   \n",
       "\n",
       "                Start                 End Timelimit Suspended ExclusiveCPU  \\\n",
       "0 2023-07-27 08:13:36 2023-07-27 09:35:05  02:00:00  00:00:00        False   \n",
       "\n",
       "  ExclusiveOverlapping Exclusive SharedSameUser                  UTCStart  \\\n",
       "0                False     False           True 2023-07-27 07:13:36+00:00   \n",
       "\n",
       "                     UTCEnd  \n",
       "0 2023-07-27 08:35:05+00:00  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3278d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lPowerTest = []\n",
    "\n",
    "for tTick in list(range(1690355610, 1690360500, 30)):\n",
    "    if tTick < (1690355610 + 1800):\n",
    "        lPowerTest.append([tTick, 300])\n",
    "    elif (1690355610 + 1800) < tTick and tTick < (1690355610 + 3089):\n",
    "        lPowerTest.append([tTick, 150])\n",
    "    elif tTick > (1690355610 + 3089):\n",
    "        lPowerTest.append([tTick, 300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "45c9eee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "SOCKSHTTPConnectionPool(host='128.232.227.113', port=8427): Max retries exceeded with url: /api/v1/query_range (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x0000022D6046A4C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\socks.py:787\u001b[0m, in \u001b[0;36msocksocket.connect\u001b[1;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Initial connection to proxy server.\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m     \u001b[39msuper\u001b[39;49m(socksocket, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mconnect(proxy_addr)\n\u001b[0;32m    789\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    790\u001b[0m     \u001b[39m# Error while connecting to proxy\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProxyConnectionError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\contrib\\socks.py:96\u001b[0m, in \u001b[0;36mSOCKSConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     conn \u001b[39m=\u001b[39m socks\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m     97\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhost, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[0;32m     98\u001b[0m         proxy_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39msocks_version\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     99\u001b[0m         proxy_addr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mproxy_host\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    100\u001b[0m         proxy_port\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mproxy_port\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    101\u001b[0m         proxy_username\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    102\u001b[0m         proxy_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mpassword\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    103\u001b[0m         proxy_rdns\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mrdns\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    104\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    105\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[0;32m    106\u001b[0m     )\n\u001b[0;32m    108\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\socks.py:209\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m err:\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    211\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgai returned empty list.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\socks.py:199\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[0;32m    197\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 199\u001b[0m sock\u001b[39m.\u001b[39;49mconnect((remote_host, remote_port))\n\u001b[0;32m    200\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\socks.py:47\u001b[0m, in \u001b[0;36mset_self_blocking.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetblocking(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\socks.py:800\u001b[0m, in \u001b[0;36msocksocket.connect\u001b[1;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[0;32m    799\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m due to: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, msg, error)\n\u001b[1;32m--> 800\u001b[0m     \u001b[39mraise\u001b[39;00m ProxyConnectionError(msg, error)\n\u001b[0;32m    801\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mProxyConnectionError\u001b[0m: Error connecting to SOCKS5 proxy localhost:49152: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[0;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1013\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    952\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\contrib\\socks.py:127\u001b[0m, in \u001b[0;36mSOCKSConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    128\u001b[0m             \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m error\n\u001b[0;32m    129\u001b[0m         )\n\u001b[0;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.contrib.socks.SOCKSConnection object at 0x0000022D6046A4C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: SOCKSHTTPConnectionPool(host='128.232.227.113', port=8427): Max retries exceeded with url: /api/v1/query_range (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x0000022D6046A4C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m getPowerJob(\u001b[39m0\u001b[39;49m, dfTest)\n",
      "Cell \u001b[1;32mIn[140], line 29\u001b[0m, in \u001b[0;36mgetPowerJob\u001b[1;34m(jobID, df)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mloc[jobID] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     28\u001b[0m     sNode \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[jobID, \u001b[39m'\u001b[39m\u001b[39mNodeList\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m getPowerNode(jobID, df, sNode)\n\u001b[0;32m     31\u001b[0m lNodeList \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mloc[jobID, \u001b[39m'\u001b[39m\u001b[39mNodeList\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     33\u001b[0m dTotalWattHours \u001b[39m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[140], line 90\u001b[0m, in \u001b[0;36mgetPowerNode\u001b[1;34m(jobID, df, sNode)\u001b[0m\n\u001b[0;32m     81\u001b[0m end \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mNodeList\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m sNode]\u001b[39m.\u001b[39mloc[jobID, \u001b[39m'\u001b[39m\u001b[39mUTCEnd\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39mT\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mSZ\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m     84\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mamperageProbeReading\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39malias=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msNode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, amperageProbeLocationName=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem Board Pwr Consumption\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m     85\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m'\u001b[39m: start,\n\u001b[0;32m     86\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m : end,\n\u001b[0;32m     87\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m30s\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     88\u001b[0m }\n\u001b[1;32m---> 90\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mput(\n\u001b[0;32m     91\u001b[0m     url, \n\u001b[0;32m     92\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m     93\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m     94\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m     95\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\n\u001b[0;32m     96\u001b[0m )  \n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(response\u001b[39m.\u001b[39mjson()[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:130\u001b[0m, in \u001b[0;36mput\u001b[1;34m(url, data, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mput\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a PUT request.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mput\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: SOCKSHTTPConnectionPool(host='128.232.227.113', port=8427): Max retries exceeded with url: /api/v1/query_range (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x0000022D6046A4C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "getPowerJob(0, dfTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
